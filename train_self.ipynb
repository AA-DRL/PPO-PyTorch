{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : NVIDIA GeForce RTX 3060 Ti\n",
      "============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AARL\\lib\\site-packages\\gym\\envs\\registration.py:440: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "############################### Import libraries ###############################\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "# import roboschool\n",
    "import pybullet_envs\n",
    "\n",
    "\n",
    "################################## set device ##################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "    \n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################## PPO Policy ##################################\n",
    "\n",
    "\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "    \n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Tanh()\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        \n",
    "        return action.detach(), action_logprob.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "            \n",
    "            # for single action continuous environments\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "        \n",
    "        return action_logprobs, state_values, dist_entropy\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        \n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "                    ])\n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        \n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "            \n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "            \n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
    "\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "\n",
    "        \n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "            \n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "\n",
    "            # Finding Surrogate Loss\n",
    "            advantages = rewards - state_values.detach()   \n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "\n",
    "            # final loss of clipped objective PPO\n",
    "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
    "            \n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "training environment name : CartPole-v1\n",
      "current logging run number for CartPole-v1 :  6\n",
      "logging at : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_6.csv\n",
      "save checkpoint path : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "max training timesteps :  100000\n",
      "max timesteps per episode :  400\n",
      "model saving frequency : 20000 timesteps\n",
      "log frequency : 800 timesteps\n",
      "printing average reward over episodes in last : 1600 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "state space dimension :  4\n",
      "action space dimension :  2\n",
      "--------------------------------------------------------------------------------------------\n",
      "Initializing a discrete action space policy\n",
      "--------------------------------------------------------------------------------------------\n",
      "PPO update frequency : 1600 timesteps\n",
      "PPO K epochs :  40\n",
      "PPO epsilon clip :  0.2\n",
      "discount factor (gamma) :  0.99\n",
      "--------------------------------------------------------------------------------------------\n",
      "optimizer learning rate actor :  0.0003\n",
      "optimizer learning rate critic :  0.001\n",
      "============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AARL\\lib\\site-packages\\gym\\core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\User\\anaconda3\\envs\\AARL\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training at (GMT) :  2022-08-27 04:08:14\n",
      "============================================================================================\n",
      "Episode : 70 \t\t Timestep : 1600 \t\t Average Reward : 22.66\n",
      "Episode : 132 \t\t Timestep : 3200 \t\t Average Reward : 26.0\n",
      "Episode : 177 \t\t Timestep : 4800 \t\t Average Reward : 33.18\n",
      "Episode : 211 \t\t Timestep : 6400 \t\t Average Reward : 49.44\n",
      "Episode : 231 \t\t Timestep : 8000 \t\t Average Reward : 78.4\n",
      "Episode : 246 \t\t Timestep : 9600 \t\t Average Reward : 108.6\n",
      "Episode : 256 \t\t Timestep : 11200 \t\t Average Reward : 161.6\n",
      "Episode : 262 \t\t Timestep : 12800 \t\t Average Reward : 224.83\n",
      "Episode : 273 \t\t Timestep : 14400 \t\t Average Reward : 160.73\n",
      "Episode : 281 \t\t Timestep : 16000 \t\t Average Reward : 194.12\n",
      "Episode : 291 \t\t Timestep : 17600 \t\t Average Reward : 171.9\n",
      "Episode : 299 \t\t Timestep : 19200 \t\t Average Reward : 174.88\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:21\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 306 \t\t Timestep : 20800 \t\t Average Reward : 238.43\n",
      "Episode : 314 \t\t Timestep : 22400 \t\t Average Reward : 206.75\n",
      "Episode : 320 \t\t Timestep : 24000 \t\t Average Reward : 273.83\n",
      "Episode : 324 \t\t Timestep : 25600 \t\t Average Reward : 337.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\AIMM\\AARL\\PPO-PyTorch\\train_self.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 189>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m current_ep_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_ep_len\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m     \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=195'>196</a>\u001b[0m     \u001b[39m# select action with policy\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m     action \u001b[39m=\u001b[39m ppo_agent\u001b[39m.\u001b[39;49mselect_action(state)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=197'>198</a>\u001b[0m     state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=199'>200</a>\u001b[0m     \u001b[39m# saving reward and is_terminals\u001b[39;00m\n",
      "\u001b[1;32md:\\AIMM\\AARL\\PPO-PyTorch\\train_self.ipynb Cell 2\u001b[0m in \u001b[0;36mPPO.select_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=225'>226</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m     state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(state)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m     action, action_logprob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_old\u001b[39m.\u001b[39;49mact(state)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mstates\u001b[39m.\u001b[39mappend(state)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mactions\u001b[39m.\u001b[39mappend(action)\n",
      "\u001b[1;32md:\\AIMM\\AARL\\PPO-PyTorch\\train_self.ipynb Cell 2\u001b[0m in \u001b[0;36mActorCritic.act\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     dist \u001b[39m=\u001b[39m Categorical(action_probs)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m action \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39msample()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m action_logprob \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39;49mlog_prob(action)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W1sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39mreturn\u001b[39;00m action\u001b[39m.\u001b[39mdetach(), action_logprob\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\AARL\\lib\\site-packages\\torch\\distributions\\categorical.py:121\u001b[0m, in \u001b[0;36mCategorical.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value):\n\u001b[0;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args:\n\u001b[1;32m--> 121\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_sample(value)\n\u001b[0;32m    122\u001b[0m     value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    123\u001b[0m     value, log_pmf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbroadcast_tensors(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\AARL\\lib\\site-packages\\torch\\distributions\\distribution.py:291\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39massert\u001b[39;00m support \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m valid \u001b[39m=\u001b[39m support\u001b[39m.\u001b[39;49mcheck(value)\n\u001b[0;32m    292\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m    293\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    294\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected value argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\AARL\\lib\\site-packages\\torch\\distributions\\constraints.py:257\u001b[0m, in \u001b[0;36m_IntegerInterval.check\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(\u001b[39mself\u001b[39m, value):\n\u001b[1;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m (value \u001b[39m%\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39m&\u001b[39;49m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_bound \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m value) \u001b[39m&\u001b[39m (value \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupper_bound)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "################################### Training ###################################\n",
    "\n",
    "\n",
    "####### initialize environment hyperparameters ######\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "has_continuous_action_space = False\n",
    "\n",
    "max_ep_len = 400                    # max timesteps in one episode\n",
    "max_training_timesteps = int(1e5)   # break training loop if timeteps > max_training_timesteps\n",
    "\n",
    "print_freq = max_ep_len * 4     # print avg reward in the interval (in num timesteps)\n",
    "log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
    "save_model_freq = int(2e4)      # save model frequency (in num timesteps)\n",
    "\n",
    "action_std = None\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "## Note : print/log frequencies should be > than max_ep_len\n",
    "\n",
    "\n",
    "################ PPO hyperparameters ################\n",
    "\n",
    "\n",
    "update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
    "K_epochs = 40               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.0003       # learning rate for actor network\n",
    "lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "random_seed = 0         # set random seed if required (0 = no random seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\"training environment name : \" + env_name)\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "\n",
    "###################### logging ######################\n",
    "\n",
    "#### log files for multiple runs are NOT overwritten\n",
    "\n",
    "log_dir = \"PPO_logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "log_dir = log_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "#### get number of log files in log directory\n",
    "run_num = 0\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "run_num = len(current_num_files)\n",
    "\n",
    "\n",
    "#### create new log file for each run \n",
    "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "\n",
    "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
    "print(\"logging at : \" + log_f_name)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "################### checkpointing ###################\n",
    "\n",
    "run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
    "\n",
    "directory = \"PPO_preTrained\"\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "directory = directory + '/' + env_name + '/'\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"save checkpoint path : \" + checkpoint_path)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "############# print all hyperparameters #############\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"max training timesteps : \", max_training_timesteps)\n",
    "print(\"max timesteps per episode : \", max_ep_len)\n",
    "\n",
    "print(\"model saving frequency : \" + str(save_model_freq) + \" timesteps\")\n",
    "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
    "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"state space dimension : \", state_dim)\n",
    "print(\"action space dimension : \", action_dim)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "if has_continuous_action_space:\n",
    "    print(\"Initializing a continuous action space policy\")\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"starting std of action distribution : \", action_std)\n",
    "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
    "    print(\"minimum std of action distribution : \", min_action_std)\n",
    "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
    "\n",
    "else:\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\") \n",
    "print(\"PPO K epochs : \", K_epochs)\n",
    "print(\"PPO epsilon clip : \", eps_clip)\n",
    "print(\"discount factor (gamma) : \", gamma)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"optimizer learning rate actor : \", lr_actor)\n",
    "print(\"optimizer learning rate critic : \", lr_critic)\n",
    "\n",
    "if random_seed:\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"setting random seed to \", random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    env.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "################# training procedure ################\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "\n",
    "# track total training time\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# logging file\n",
    "log_f = open(log_f_name,\"w+\")\n",
    "log_f.write('episode,timestep,reward\\n')\n",
    "\n",
    "\n",
    "# printing and logging variables\n",
    "print_running_reward = 0\n",
    "print_running_episodes = 0\n",
    "\n",
    "log_running_reward = 0\n",
    "log_running_episodes = 0\n",
    "\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "\n",
    "\n",
    "# training loop\n",
    "while time_step <= max_training_timesteps:\n",
    "    \n",
    "    state = env.reset()\n",
    "    current_ep_reward = 0\n",
    "\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        \n",
    "        # select action with policy\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # saving reward and is_terminals\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done)\n",
    "        \n",
    "        time_step +=1\n",
    "        current_ep_reward += reward\n",
    "\n",
    "        # update PPO agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent.update()\n",
    "\n",
    "        # if continuous action space; then decay action std of ouput action distribution\n",
    "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
    "            ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "\n",
    "        # log in logging file\n",
    "        if time_step % log_freq == 0:\n",
    "\n",
    "            # log average reward till last episode\n",
    "            log_avg_reward = log_running_reward / log_running_episodes\n",
    "            log_avg_reward = round(log_avg_reward, 4)\n",
    "\n",
    "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
    "            log_f.flush()\n",
    "\n",
    "            log_running_reward = 0\n",
    "            log_running_episodes = 0\n",
    "\n",
    "        # printing average reward\n",
    "        if time_step % print_freq == 0:\n",
    "\n",
    "            # print average reward till last episode\n",
    "            print_avg_reward = print_running_reward / print_running_episodes\n",
    "            print_avg_reward = round(print_avg_reward, 2)\n",
    "\n",
    "            print(\"Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward))\n",
    "\n",
    "            print_running_reward = 0\n",
    "            print_running_episodes = 0\n",
    "            \n",
    "        # save model weights\n",
    "        if time_step % save_model_freq == 0:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"saving model at : \" + checkpoint_path)\n",
    "            ppo_agent.save(checkpoint_path)\n",
    "            print(\"model saved\")\n",
    "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            \n",
    "        # break; if the episode is over\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print_running_reward += current_ep_reward\n",
    "    print_running_episodes += 1\n",
    "\n",
    "    log_running_reward += current_ep_reward\n",
    "    log_running_episodes += 1\n",
    "\n",
    "    i_episode += 1\n",
    "\n",
    "\n",
    "log_f.close()\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print total training time\n",
    "print(\"============================================================================================\")\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "print(\"Finished training at (GMT) : \", end_time)\n",
    "print(\"Total training time  : \", end_time - start_time)\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "host = '127.0.0.1'\n",
    "port = 1234\n",
    "ID = \"RL\"\n",
    "\n",
    "ClientSocket = socket.socket()\n",
    "\n",
    "print('Waiting for connection')\n",
    "try:\n",
    "    ClientSocket.connect((host, port))\n",
    "except socket.error as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success connect, Check ID\n",
      "You are now connected to server... send \"Close\" to stop\n"
     ]
    }
   ],
   "source": [
    "Response = ClientSocket.recv(2048)\n",
    "print(Response.decode('utf-8'))\n",
    "ClientSocket.send(str.encode(f\"I'm {ID}\"))\n",
    "Response = ClientSocket.recv(2048)\n",
    "print(Response.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClientSocket.send(str(\"LLL\").encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2\n",
      "R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.80001831, 151.5375061 , 182.92501831, 481.2749939 ]), 3: array([198.45001221, 164.02500916, 224.4375    , 456.29998779])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.80001831, 151.5375061 , 182.92501831, 481.2749939 ]), 3: array([198.57470995, 164.28514055, 224.18810451, 455.77977204])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.80001831, 151.5375061 , 182.92501831, 481.2749939 ]), 3: array([198.48836579, 164.10939594, 224.36079284, 456.13122948])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.80001831, 151.5375061 , 182.92501831, 481.2749939 ]), 3: array([198.45788519, 164.04718406, 224.42175403, 456.25564199])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.7280873 , 151.29305048, 183.06885823, 481.76392724]), 3: array([198.56068117, 164.02669821, 224.21616207, 455.80777173])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.71962207, 151.2096654 , 183.08578115, 481.93070494]), 3: array([198.59052794, 164.02046768, 224.15646854, 455.65337751])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.7341864 , 151.18300281, 183.05665007, 481.98403254]), 3: array([198.5942947 , 164.01905333, 224.14893501, 455.60294043])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.7571067 , 151.17628598, 183.01080886, 481.9974668 ]), 3: array([198.58875463, 164.01920293, 224.16001515, 455.58923882])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.78277625, 151.17633968, 182.95946977, 481.99735939]), 3: array([198.58004379, 164.01979367, 224.17743684, 455.58817487])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.80891126, 151.17845161, 182.90719995, 481.99313535]), 3: array([198.57046444, 164.0204482 , 224.19659553, 455.59108973])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.83450022, 151.18097572, 182.85602225, 481.9880869 ]), 3: array([198.56090335, 164.02105086, 224.21571772, 455.59492797])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.85905282, 151.18337462, 182.80691726, 481.98328889]), 3: array([198.55171169, 164.02157565, 224.23410104, 455.59866943])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.88231615, 151.18550422, 182.7603908 , 481.9790295 ]), 3: array([198.54303071, 164.02202515, 224.25146299, 455.60202216])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.90416163, 151.18735314, 182.7167    , 481.97533149]), 3: array([198.53491428, 164.02240934, 224.26769585, 455.60494418])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.9245353 , 151.18894943, 182.67595281, 481.97213876]), 3: array([198.52737634, 164.0227387 , 224.28277173, 455.607471  ])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.9434323 , 151.19032851, 182.63815893, 481.96938047]), 3: array([198.52041033, 164.02302234, 224.29670375, 455.60965542])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.96088149, 151.19152319, 182.60326067, 481.966991  ]), 3: array([198.51399806, 164.02326769, 224.3095283 , 455.61154823])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.97693475, 151.19256136, 182.57115424, 481.96491457]), 3: array([198.50811432, 164.02348075, 224.32129578, 455.61319322])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([415.9916592 , 151.19346612, 182.54170543, 481.96310498]), 3: array([198.50272975, 164.02366638, 224.33206492, 455.61462685])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([416.00513124, 151.19425652, 182.51476142, 481.9615241 ]), 3: array([198.49781274, 164.02382852, 224.34189893, 455.61587929])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([416.01743216, 151.19494839, 182.49015963, 481.96014029]), 3: array([198.4933308 , 164.02397044, 224.3508628 , 455.6169756 ])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([416.02864485, 151.19555497, 182.46773432, 481.95892707]), 3: array([198.48925154, 164.02409486, 224.35902133, 455.61793676])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([416.0388514 , 151.19608744, 182.44732125, 481.9578621 ]), 3: array([198.48554336, 164.02420407, 224.3664377 , 455.61878048])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([416.04813154, 151.19655529, 182.42876101, 481.95692634]), 3: array([198.48217592, 164.02430004, 224.37317257, 455.61952184])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([416.05656148, 151.1969667 , 182.41190117, 481.9561035 ]), 3: array([198.47912047, 164.02438442, 224.37928346, 455.62017374])}\n",
      "M2R|dict|{1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ]), 2: array([416.06421325, 151.19732867, 182.39659767, 481.95537952]), 3: array([198.47635001, 164.02445867, 224.38482439, 455.62074733])}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{}\n",
      "M2R|dict|{2: array([428.33198175, 180.09054822, 169.88489559, 436.35978488]), 3: array([185.6765567 , 188.57291425, 202.55703798, 425.73228485])}\n",
      "M2R|dict|{2: array([418.32922743, 159.74455766, 181.42264615, 468.4663915 ]), 3: array([197.46566424, 171.98250046, 213.15779503, 446.51908624]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.6776187 , 153.89393965, 184.29089805, 477.6988405 ]), 3: array([199.98498101, 166.56999494, 217.24851734, 452.74527667]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([414.80321142, 151.66053663, 185.1102002 , 481.22322327]), 3: array([200.71487379, 164.52103651, 219.23039602, 455.09830926]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([414.60865967, 150.86334392, 185.16752838, 482.48122505]), 3: array([200.78650036, 163.78662572, 220.30763678, 455.93809683]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([414.65732982, 150.62019059, 184.96899758, 482.86493569]), 3: array([200.63595176, 163.55749325, 220.97785546, 456.19689032]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([414.78112188, 150.58224133, 184.70562583, 482.92482728]), 3: array([200.4270914 , 163.51591184, 221.45036048, 456.24049095]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([414.91880351, 150.6158152 , 184.44424123, 482.87185237]), 3: array([200.21751757, 163.54021596, 221.81515788, 456.2088513 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.04968923, 150.67069996, 184.20531709, 482.78524748]), 3: array([200.02517558, 163.5846348 , 222.11330963, 456.15455425]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.1679557 , 150.72851794, 183.99285159, 482.69401326]), 3: array([199.85384892, 163.63236143, 222.36534356, 456.09686347]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.27298551, 150.78292816, 183.8054406 , 482.60815605]), 3: array([199.70262305, 163.67755345, 222.58272824, 456.04244042]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.36581261, 150.83208877, 183.64024976, 482.53058241]), 3: array([199.56929647, 163.71847239, 222.77262171, 455.99323603]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.4478539 , 150.87579624, 183.49436059, 482.46161359]), 3: array([199.45154733, 163.75487744, 222.93992644, 455.94948669]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.52048573, 150.91440514, 183.36516802, 482.40069011]), 3: array([199.34728574, 163.78704108, 223.08823854, 455.91084476]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.58492526, 150.94842562, 183.25045011, 482.347007  ]), 3: array([199.25472239, 163.81538213, 223.2203245 , 455.87679931]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.6422165 , 150.97837804, 183.14833543, 482.29974313]), 3: array([199.17234724, 163.84033327, 223.33838388, 455.84682761]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.69324822, 151.00474459, 183.05724716, 482.25813764]), 3: array([199.09888647, 163.86229669, 223.44420751, 455.82044538]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.73877817, 151.02795675, 182.97584939, 482.22150967]), 3: array([199.03326005, 163.88163244, 223.53928015, 455.79721971]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.7794556 , 151.04839545, 182.90300221, 482.18925812]), 3: array([198.97454588, 163.89865825, 223.62485087, 455.77676877]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.81584011, 151.06639541, 182.83772575, 482.16085481]), 3: array([198.92195101, 163.91365314, 223.70198322, 455.75875735]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.84841682, 151.08225034, 182.779172  , 482.13583629]), 3: array([198.87478901, 163.9268618 , 223.77159215, 455.74289152]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.87760854, 151.09621793, 182.7266026 , 482.11379593]), 3: array([198.83246209, 163.93849883, 223.83447169, 455.72891348]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.90378554, 151.10852439, 182.67937122, 482.09437676]), 3: array([198.7944469 , 163.94875256, 223.89131608, 455.71659703]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.92727331, 151.11936843, 182.63690954, 482.07726525]), 3: array([198.76028326, 163.95778839, 223.9427362 , 455.70574347]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.94835904, 151.12892468, 182.5987159 , 482.06218583]), 3: array([198.72956499, 163.96575168, 223.98927246, 455.69617822]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.96729684, 151.13734668, 182.564346  , 482.0488962 ]), 3: array([198.70193238, 163.97277024, 224.03140509, 455.68774775]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.9843121 , 151.14476954, 182.53340527, 482.03718319]), 3: array([198.67706605, 163.97895651, 224.06956247, 455.68031699]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([415.99960518, 151.15131212, 182.50554248, 482.02685923]), 3: array([198.65468176, 163.98440945, 224.10412793, 455.67376708]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.01335449, 151.15707907, 182.48044438, 482.01775918]), 3: array([198.63452604, 163.98921619, 224.13544535, 455.66799338]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.02571913, 151.16216253, 182.45783109, 482.00973766]), 3: array([198.61637254, 163.99345345, 224.16382393, 455.66290372]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.0368412 , 151.16664365, 182.43745224, 482.00266661]), 3: array([198.6000188 , 163.99718879, 224.18954213, 455.65841695]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.04684769, 151.17059391, 182.41908357, 481.99643325]), 3: array([198.58528356, 164.00048175, 224.2128511 , 455.65446155]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.05585224, 151.17407627, 182.40252401, 481.99093821]), 3: array([198.57200434, 164.00338477, 224.23397763, 455.65097454]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.06395662, 151.17714622, 182.38759313, 481.98609394]), 3: array([198.56003542, 164.00594406, 224.2531267 , 455.64790039]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.071252  , 151.17985264, 182.37412893, 481.9818233 ]), 3: array([198.549246  , 164.00820037, 224.27048372, 455.64519018]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.07782013, 151.18223861, 182.36198584, 481.97805831]), 3: array([198.53951859, 164.01018958, 224.28621648, 455.64280081]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.08373434, 151.18434211, 182.351033  , 481.97473907]), 3: array([198.53074763, 164.01194332, 224.30047694, 455.64069427]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.08906045, 151.18619659, 182.34115271, 481.97181276]), 3: array([198.5228382 , 164.01348949, 224.31340272, 455.63883706]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.09385754, 151.18783156, 182.33223909, 481.96923284]), 3: array([198.51570497, 164.01485266, 224.32511853, 455.63719967]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.09817867, 151.189273  , 182.32419684, 481.9669583 ]), 3: array([198.50927114, 164.01605449, 224.33573742, 455.63575606]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1020715 , 151.19054383, 182.31694016, 481.96495297]), 3: array([198.50346761, 164.01711409, 224.34536183, 455.6344833 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.10557888, 151.19166425, 182.3103918 , 481.96318498]), 3: array([198.49823219, 164.0180483 , 224.35408466, 455.63336116]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.10873928, 151.19265208, 182.30448217, 481.96162623]), 3: array([198.49350888, 164.01887195, 224.36199011, 455.63237182]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.11158733, 151.193523  , 182.29914859, 481.96025195]), 3: array([198.48924727, 164.01959813, 224.36915456, 455.63149955]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.11415415, 151.19429085, 182.29433458, 481.95904031]), 3: array([198.48540193, 164.02023839, 224.37564725, 455.6307305 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.11646772, 151.19496783, 182.28998924, 481.95797205]), 3: array([198.48193195, 164.02080288, 224.38153097, 455.63005245]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.11855322, 151.19556471, 182.28606669, 481.9570302 ]), 3: array([198.47880049, 164.02130057, 224.38686265, 455.62945463]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1204333 , 151.19609095, 182.28252559, 481.95619981]), 3: array([198.47597432, 164.02173938, 224.39169393, 455.62892756]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.12212834, 151.19655493, 182.27932864, 481.95546767]), 3: array([198.47342352, 164.02212626, 224.39607163, 455.62846285]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.12365667, 151.196964  , 182.27644224, 481.95482217]), 3: array([198.47112112, 164.02246736, 224.40003819, 455.62805312]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.12503482, 151.19732467, 182.27383608, 481.95425305]), 3: array([198.46904279, 164.02276811, 224.40363211, 455.62769188]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.12627763, 151.19764266, 182.27148282, 481.95375127]), 3: array([198.46716663, 164.02303326, 224.40688828, 455.62737338]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.12739848, 151.19792302, 182.26935781, 481.95330887]), 3: array([198.46547287, 164.02326705, 224.40983837, 455.62709256]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.12840943, 151.19817021, 182.26743883, 481.95291881]), 3: array([198.46394369, 164.02347317, 224.41251105, 455.62684498]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1293213 , 151.19838816, 182.26570579, 481.9525749 ]), 3: array([198.46256303, 164.02365491, 224.41493233, 455.62662668]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13014388, 151.19858031, 182.26414063, 481.95227169]), 3: array([198.46131639, 164.02381514, 224.4171258 , 455.62643422]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13088595, 151.19874973, 182.262727  , 481.95200435]), 3: array([198.4601907 , 164.02395641, 224.41911282, 455.62626452]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13155545, 151.1988991 , 182.26145018, 481.95176864]), 3: array([198.45917419, 164.02408097, 224.42091279, 455.62611491]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13215951, 151.1990308 , 182.26029688, 481.95156083]), 3: array([198.45825621, 164.02419079, 224.42254325, 455.625983  ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13270457, 151.19914692, 182.2592551 , 481.9513776 ]), 3: array([198.45742718, 164.02428761, 224.42402014, 455.62586669]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13319642, 151.1992493 , 182.25831402, 481.95121605]), 3: array([198.45667845, 164.02437299, 224.42535787, 455.62576415]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13364027, 151.19933956, 182.25746387, 481.95107361]), 3: array([198.4560022 , 164.02444825, 224.42656954, 455.62567374]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13404085, 151.19941915, 182.25669584, 481.95094803]), 3: array([198.45539139, 164.02451462, 224.42766698, 455.62559402]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13440239, 151.19948932, 182.25600197, 481.95083731]), 3: array([198.45483966, 164.02457313, 224.42866095, 455.62552374]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13472872, 151.19955118, 182.25537507, 481.95073968]), 3: array([198.45434128, 164.02462472, 224.42956118, 455.62546177]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13502328, 151.19960573, 182.25480866, 481.95065361]), 3: array([198.45389108, 164.0246702 , 224.43037648, 455.62540714]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13528918, 151.19965382, 182.25429688, 481.95057772]), 3: array([198.45348437, 164.02471031, 224.43111486, 455.62535897]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13552922, 151.19969623, 182.25383445, 481.95051081]), 3: array([198.45311694, 164.02474567, 224.43178355, 455.6253165 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13574593, 151.19973361, 182.25341659, 481.95045182]), 3: array([198.45278499, 164.02477684, 224.43238911, 455.62527905]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13594158, 151.19976657, 182.253039  , 481.95039981]), 3: array([198.45248508, 164.02480433, 224.43293751, 455.62524603]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13611824, 151.19979564, 182.25269779, 481.95035395]), 3: array([198.45221411, 164.02482856, 224.43343411, 455.62521692]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13627775, 151.19982126, 182.25238944, 481.95031351]), 3: array([198.45196927, 164.02484993, 224.43388381, 455.62519126]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13642178, 151.19984385, 182.25211077, 481.95027787]), 3: array([198.45174804, 164.02486877, 224.43429102, 455.62516863]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13655185, 151.19986377, 182.25185893, 481.95024643]), 3: array([198.45154814, 164.02488538, 224.43465975, 455.62514868]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13666931, 151.19988133, 182.25163132, 481.95021872]), 3: array([198.45136749, 164.02490002, 224.43499363, 455.62513109]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13677538, 151.19989682, 182.25142561, 481.95019429]), 3: array([198.45120426, 164.02491293, 224.43529594, 455.62511558]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13687119, 151.19991047, 182.25123969, 481.95017274]), 3: array([198.45105674, 164.02492432, 224.43556968, 455.6251019 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13695772, 151.19992251, 182.25107164, 481.95015375]), 3: array([198.45092342, 164.02493436, 224.43581752, 455.62508985]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13703587, 151.19993312, 182.25091975, 481.950137  ]), 3: array([198.45080294, 164.02494321, 224.43604193, 455.62507922]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13710646, 151.19994248, 182.25078246, 481.95012224]), 3: array([198.45069406, 164.02495101, 224.4362451 , 455.62506984]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13717023, 151.19995073, 182.25065837, 481.95010922]), 3: array([198.45059565, 164.02495789, 224.43642905, 455.62506158]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13722783, 151.199958  , 182.25054619, 481.95009774]), 3: array([198.4505067 , 164.02496395, 224.43659559, 455.62505429]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13727986, 151.19996441, 182.25044479, 481.95008762]), 3: array([198.45042631, 164.0249693 , 224.43674636, 455.62504787]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13732687, 151.19997007, 182.25035314, 481.9500787 ]), 3: array([198.45035365, 164.02497402, 224.43688286, 455.62504221]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13736933, 151.19997505, 182.25027028, 481.95007083]), 3: array([198.45028797, 164.02497817, 224.43700643, 455.62503721]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1374077 , 151.19997945, 182.25019538, 481.9500639 ]), 3: array([198.45022861, 164.02498184, 224.4371183 , 455.62503281]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13744236, 151.19998333, 182.25012767, 481.95005778]), 3: array([198.45017495, 164.02498507, 224.43721957, 455.62502893]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13747368, 151.19998674, 182.25006646, 481.95005239]), 3: array([198.45012645, 164.02498792, 224.43731125, 455.62502551]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13750197, 151.19998976, 182.25001113, 481.95004763]), 3: array([198.45008261, 164.02499043, 224.43739423, 455.62502249]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13752754, 151.19999241, 182.2499611 , 481.95004344]), 3: array([198.45004298, 164.02499265, 224.43746935, 455.62501983]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13755063, 151.19999475, 182.24991588, 481.95003975]), 3: array([198.45000715, 164.0249946 , 224.43753734, 455.62501748]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13757151, 151.19999682, 182.249875  , 481.95003649]), 3: array([198.44997477, 164.02499632, 224.43759889, 455.62501541]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13759036, 151.19999864, 182.24983804, 481.95003362]), 3: array([198.44994549, 164.02499784, 224.4376546 , 455.62501359]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1376074 , 151.20000025, 182.24980463, 481.95003108]), 3: array([198.44991903, 164.02499918, 224.43770502, 455.62501198]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1376228 , 151.20000166, 182.24977442, 481.95002885]), 3: array([198.44989511, 164.02500036, 224.43775065, 455.62501056]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13763671, 151.20000291, 182.24974712, 481.95002688]), 3: array([198.44987348, 164.0250014 , 224.43779196, 455.62500931]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13764928, 151.20000401, 182.24972243, 481.95002514]), 3: array([198.44985394, 164.02500232, 224.43782934, 455.62500821]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13766064, 151.20000498, 182.24970012, 481.95002361]), 3: array([198.44983627, 164.02500313, 224.43786316, 455.62500724]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13767091, 151.20000583, 182.24967995, 481.95002226]), 3: array([198.44982029, 164.02500384, 224.43789377, 455.62500638]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13768018, 151.20000659, 182.24966171, 481.95002107]), 3: array([198.44980585, 164.02500447, 224.43792148, 455.62500563]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13768856, 151.20000725, 182.24964523, 481.95002002]), 3: array([198.4497928 , 164.02500502, 224.43794654, 455.62500496]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13769613, 151.20000784, 182.24963033, 481.9500191 ]), 3: array([198.449781  , 164.02500551, 224.43796922, 455.62500438]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13770298, 151.20000836, 182.24961686, 481.95001828]), 3: array([198.44977034, 164.02500594, 224.43798974, 455.62500386]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13770916, 151.20000881, 182.24960469, 481.95001757]), 3: array([198.4497607 , 164.02500632, 224.4380083 , 455.6250034 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13771474, 151.20000921, 182.24959369, 481.95001693]), 3: array([198.44975199, 164.02500666, 224.4380251 , 455.625003  ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13771978, 151.20000957, 182.24958375, 481.95001637]), 3: array([198.44974412, 164.02500695, 224.43804029, 455.62500264]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13772434, 151.20000988, 182.24957476, 481.95001588]), 3: array([198.44973701, 164.02500721, 224.43805403, 455.62500233]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13772846, 151.20001015, 182.24956664, 481.95001545]), 3: array([198.44973058, 164.02500744, 224.43806646, 455.62500206]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13773218, 151.2000104 , 182.24955931, 481.95001506]), 3: array([198.44972477, 164.02500765, 224.4380777 , 455.62500181]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13773553, 151.20001061, 182.24955268, 481.95001472]), 3: array([198.44971952, 164.02500783, 224.43808787, 455.6250016 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13773857, 151.2000108 , 182.2495467 , 481.95001443]), 3: array([198.44971478, 164.02500798, 224.43809706, 455.62500141]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377413 , 151.20001097, 182.24954129, 481.95001416]), 3: array([198.44971049, 164.02500812, 224.43810536, 455.62500124]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13774378, 151.20001111, 182.24953641, 481.95001393]), 3: array([198.44970662, 164.02500824, 224.43811287, 455.6250011 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13774601, 151.20001124, 182.249532  , 481.95001373]), 3: array([198.44970313, 164.02500835, 224.43811966, 455.62500097]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13774802, 151.20001136, 182.24952802, 481.95001355]), 3: array([198.44969997, 164.02500845, 224.43812579, 455.62500085]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13774984, 151.20001146, 182.24952443, 481.95001339]), 3: array([198.44969713, 164.02500853, 224.43813133, 455.62500075]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775148, 151.20001155, 182.24952118, 481.95001325]), 3: array([198.44969455, 164.0250086 , 224.43813634, 455.62500066]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775296, 151.20001162, 182.24951826, 481.95001313]), 3: array([198.44969223, 164.02500867, 224.43814086, 455.62500058]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775429, 151.20001169, 182.24951562, 481.95001302]), 3: array([198.44969014, 164.02500873, 224.43814494, 455.62500051]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775549, 151.20001175, 182.24951324, 481.95001292]), 3: array([198.44968825, 164.02500878, 224.43814862, 455.62500045]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775657, 151.20001181, 182.2495111 , 481.95001284]), 3: array([198.44968655, 164.02500882, 224.43815194, 455.6250004 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775755, 151.20001186, 182.24950917, 481.95001276]), 3: array([198.44968501, 164.02500886, 224.43815494, 455.62500035]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775843, 151.2000119 , 182.24950743, 481.9500127 ]), 3: array([198.44968363, 164.0250089 , 224.43815764, 455.62500031]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775922, 151.20001193, 182.24950587, 481.95001264]), 3: array([198.44968238, 164.02500893, 224.43816007, 455.62500027]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13775993, 151.20001197, 182.24950446, 481.95001259]), 3: array([198.44968126, 164.02500895, 224.43816226, 455.62500024]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776056, 151.20001199, 182.2495032 , 481.95001254]), 3: array([198.44968025, 164.02500898, 224.43816424, 455.62500021]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776114, 151.20001202, 182.24950206, 481.9500125 ]), 3: array([198.44967935, 164.025009  , 224.43816601, 455.62500019]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776165, 151.20001204, 182.24950104, 481.95001247]), 3: array([198.44967853, 164.02500902, 224.43816761, 455.62500017]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776211, 151.20001206, 182.24950013, 481.95001244]), 3: array([198.4496778 , 164.02500903, 224.43816904, 455.62500015]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776253, 151.20001208, 182.24949931, 481.95001241]), 3: array([198.44967714, 164.02500905, 224.43817033, 455.62500013]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377629 , 151.20001209, 182.24949858, 481.95001239]), 3: array([198.44967656, 164.02500906, 224.43817148, 455.62500011]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776323, 151.20001211, 182.24949792, 481.95001236]), 3: array([198.44967603, 164.02500907, 224.43817251, 455.6250001 ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776352, 151.20001212, 182.24949734, 481.95001235]), 3: array([198.44967556, 164.02500908, 224.43817343, 455.62500009]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776378, 151.20001213, 182.24949682, 481.95001233]), 3: array([198.44967514, 164.02500909, 224.43817426, 455.62500008]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776401, 151.20001214, 182.24949636, 481.95001232]), 3: array([198.44967476, 164.0250091 , 224.43817499, 455.62500007]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776422, 151.20001215, 182.24949595, 481.9500123 ]), 3: array([198.44967443, 164.0250091 , 224.43817565, 455.62500006]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377644 , 151.20001215, 182.24949559, 481.95001229]), 3: array([198.44967414, 164.02500911, 224.43817623, 455.62500005]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776456, 151.20001216, 182.24949527, 481.95001228]), 3: array([198.44967387, 164.02500912, 224.43817674, 455.62500005]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377647 , 151.20001217, 182.24949499, 481.95001227]), 3: array([198.44967364, 164.02500912, 224.43817719, 455.62500004]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776483, 151.20001217, 182.24949475, 481.95001226]), 3: array([198.44967344, 164.02500912, 224.43817759, 455.62500004]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776493, 151.20001217, 182.24949454, 481.95001226]), 3: array([198.44967326, 164.02500913, 224.43817794, 455.62500003]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776502, 151.20001218, 182.24949435, 481.95001225]), 3: array([198.44967311, 164.02500913, 224.43817824, 455.62500003]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377651 , 151.20001218, 182.2494942 , 481.95001225]), 3: array([198.44967297, 164.02500913, 224.4381785 , 455.62500003]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776517, 151.20001218, 182.24949406, 481.95001224]), 3: array([198.44967286, 164.02500914, 224.43817873, 455.62500002]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776523, 151.20001219, 182.24949395, 481.95001224]), 3: array([198.44967276, 164.02500914, 224.43817892, 455.62500002]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776527, 151.20001219, 182.24949386, 481.95001223]), 3: array([198.44967268, 164.02500914, 224.43817908, 455.62500002]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776531, 151.20001219, 182.24949379, 481.95001223]), 3: array([198.44967261, 164.02500914, 224.43817922, 455.62500002]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776534, 151.20001219, 182.24949373, 481.95001223]), 3: array([198.44967255, 164.02500914, 224.43817933, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776536, 151.2000122 , 182.24949369, 481.95001223]), 3: array([198.44967251, 164.02500915, 224.43817942, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776538, 151.2000122 , 182.24949366, 481.95001222]), 3: array([198.44967247, 164.02500915, 224.43817948, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776539, 151.2000122 , 182.24949364, 481.95001222]), 3: array([198.44967245, 164.02500915, 224.43817953, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776539, 151.2000122 , 182.24949363, 481.95001222]), 3: array([198.44967243, 164.02500915, 224.43817956, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776539, 151.2000122 , 182.24949363, 481.95001222]), 3: array([198.44967242, 164.02500915, 224.43817958, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776538, 151.2000122 , 182.24949365, 481.95001222]), 3: array([198.44967242, 164.02500915, 224.43817958, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776537, 151.2000122 , 182.24949367, 481.95001222]), 3: array([198.44967243, 164.02500915, 224.43817957, 455.62500001]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776536, 151.2000122 , 182.2494937 , 481.95001221]), 3: array([198.44967244, 164.02500915, 224.43817955, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776534, 151.2000122 , 182.24949373, 481.95001221]), 3: array([198.44967245, 164.02500915, 224.43817951, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776532, 151.2000122 , 182.24949377, 481.95001221]), 3: array([198.44967248, 164.02500915, 224.43817947, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377653 , 151.2000122 , 182.24949382, 481.95001221]), 3: array([198.4496725 , 164.02500915, 224.43817942, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776527, 151.2000122 , 182.24949387, 481.95001221]), 3: array([198.44967253, 164.02500915, 224.43817936, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776524, 151.2000122 , 182.24949393, 481.95001221]), 3: array([198.44967256, 164.02500915, 224.43817929, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776521, 151.2000122 , 182.24949399, 481.95001221]), 3: array([198.4496726 , 164.02500915, 224.43817922, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776518, 151.20001221, 182.24949405, 481.95001221]), 3: array([198.44967264, 164.02500915, 224.43817914, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776515, 151.20001221, 182.24949412, 481.95001221]), 3: array([198.44967268, 164.02500915, 224.43817905, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776511, 151.20001221, 182.24949419, 481.95001221]), 3: array([198.44967273, 164.02500915, 224.43817896, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776507, 151.20001221, 182.24949427, 481.95001221]), 3: array([198.44967277, 164.02500915, 224.43817887, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776504, 151.20001221, 182.24949434, 481.95001221]), 3: array([198.44967282, 164.02500915, 224.43817877, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.137765  , 151.20001221, 182.24949442, 481.95001221]), 3: array([198.44967287, 164.02500915, 224.43817867, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776495, 151.20001221, 182.24949451, 481.95001221]), 3: array([198.44967293, 164.02500915, 224.43817856, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776491, 151.20001221, 182.24949459, 481.95001221]), 3: array([198.44967298, 164.02500915, 224.43817845, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776487, 151.20001221, 182.24949468, 481.95001221]), 3: array([198.44967304, 164.02500915, 224.43817834, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776482, 151.20001221, 182.24949476, 481.95001221]), 3: array([198.4496731 , 164.02500915, 224.43817822, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776478, 151.20001221, 182.24949486, 481.95001221]), 3: array([198.44967316, 164.02500915, 224.4381781 , 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776473, 151.20001221, 182.24949495, 481.95001221]), 3: array([198.44967322, 164.02500915, 224.43817798, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776469, 151.20001221, 182.24949504, 481.95001221]), 3: array([198.44967328, 164.02500915, 224.43817786, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776464, 151.20001221, 182.24949514, 481.95001221]), 3: array([198.44967334, 164.02500915, 224.43817773, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776459, 151.20001221, 182.24949523, 481.95001221]), 3: array([198.4496734 , 164.02500915, 224.43817761, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776454, 151.20001221, 182.24949533, 481.95001221]), 3: array([198.44967347, 164.02500916, 224.43817748, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776449, 151.20001221, 182.24949543, 481.95001221]), 3: array([198.44967353, 164.02500916, 224.43817735, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776444, 151.20001221, 182.24949553, 481.95001221]), 3: array([198.4496736 , 164.02500916, 224.43817721, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776439, 151.20001221, 182.24949563, 481.95001221]), 3: array([198.44967367, 164.02500916, 224.43817708, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776434, 151.20001221, 182.24949573, 481.95001221]), 3: array([198.44967373, 164.02500916, 224.43817695, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776429, 151.20001221, 182.24949583, 481.95001221]), 3: array([198.4496738 , 164.02500916, 224.43817681, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776424, 151.20001221, 182.24949594, 481.95001221]), 3: array([198.44967387, 164.02500916, 224.43817667, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776419, 151.20001221, 182.24949604, 481.95001221]), 3: array([198.44967394, 164.02500916, 224.43817653, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776413, 151.20001221, 182.24949614, 481.95001221]), 3: array([198.44967401, 164.02500916, 224.43817639, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776408, 151.20001221, 182.24949625, 481.95001221]), 3: array([198.44967408, 164.02500916, 224.43817625, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776403, 151.20001221, 182.24949636, 481.95001221]), 3: array([198.44967415, 164.02500916, 224.43817611, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776397, 151.20001221, 182.24949646, 481.95001221]), 3: array([198.44967422, 164.02500916, 224.43817596, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776392, 151.20001221, 182.24949657, 481.95001221]), 3: array([198.4496743 , 164.02500916, 224.43817582, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776387, 151.20001221, 182.24949668, 481.95001221]), 3: array([198.44967437, 164.02500916, 224.43817567, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776381, 151.20001221, 182.24949679, 481.95001221]), 3: array([198.44967444, 164.02500916, 224.43817553, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776376, 151.20001221, 182.2494969 , 481.95001221]), 3: array([198.44967452, 164.02500916, 224.43817538, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377637 , 151.20001221, 182.24949701, 481.95001221]), 3: array([198.44967459, 164.02500916, 224.43817523, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776365, 151.20001221, 182.24949712, 481.95001221]), 3: array([198.44967467, 164.02500916, 224.43817508, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776359, 151.20001221, 182.24949723, 481.95001221]), 3: array([198.44967474, 164.02500916, 224.43817493, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776353, 151.20001221, 182.24949735, 481.95001221]), 3: array([198.44967482, 164.02500916, 224.43817478, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776348, 151.20001221, 182.24949746, 481.95001221]), 3: array([198.44967489, 164.02500916, 224.43817463, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776342, 151.20001221, 182.24949757, 481.95001221]), 3: array([198.44967497, 164.02500916, 224.43817448, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776336, 151.20001221, 182.24949769, 481.95001221]), 3: array([198.44967504, 164.02500916, 224.43817433, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776331, 151.20001221, 182.2494978 , 481.95001221]), 3: array([198.44967512, 164.02500916, 224.43817417, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776325, 151.20001221, 182.24949792, 481.95001221]), 3: array([198.4496752 , 164.02500916, 224.43817402, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776319, 151.20001221, 182.24949803, 481.95001221]), 3: array([198.44967527, 164.02500916, 224.43817386, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776313, 151.20001221, 182.24949815, 481.95001221]), 3: array([198.44967535, 164.02500916, 224.43817371, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776308, 151.20001221, 182.24949826, 481.95001221]), 3: array([198.44967543, 164.02500916, 224.43817355, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776302, 151.20001221, 182.24949838, 481.95001221]), 3: array([198.44967551, 164.02500916, 224.4381734 , 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776296, 151.20001221, 182.2494985 , 481.95001221]), 3: array([198.44967559, 164.02500916, 224.43817324, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.1377629 , 151.20001221, 182.24949862, 481.95001221]), 3: array([198.44967567, 164.02500916, 224.43817308, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776284, 151.20001221, 182.24949873, 481.95001221]), 3: array([198.44967575, 164.02500916, 224.43817292, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n",
      "M2R|dict|{2: array([416.13776278, 151.20001221, 182.24949885, 481.95001221]), 3: array([198.44967583, 164.02500916, 224.43817276, 455.625     ]), 1: array([567.33752441, 122.34375763, 163.01251221, 505.40625   ])}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32md:\\AIMM\\AARL\\PPO-PyTorch\\train_self.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     Response \u001b[39m=\u001b[39m ClientSocket\u001b[39m.\u001b[39;49mrecv(\u001b[39m2048\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AIMM/AARL/PPO-PyTorch/train_self.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(Response\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 遠端主機已強制關閉一個現存的連線。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    Response = ClientSocket.recv(2048)\n",
    "    print(Response.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('AARL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9734e671354e2551e1ea6d06d65685c14f8e75cdc49fbbedd513923d64a6d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
